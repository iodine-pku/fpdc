{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Testing time of multiple part of program(faster cuda):"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T12:28:31.324655Z","iopub.status.busy":"2023-01-18T12:28:31.324239Z","iopub.status.idle":"2023-01-18T12:28:31.664916Z","shell.execute_reply":"2023-01-18T12:28:31.663797Z","shell.execute_reply.started":"2023-01-18T12:28:31.324621Z"},"trusted":true},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pycuda'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_20848\\605844005.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautoinit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpycuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdriver\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcuda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtimeit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pycuda'"]}],"source":["import pycuda.autoinit\n","import pycuda.driver as cuda\n","import numpy as np\n","import time\n","import timeit\n","from pycuda.compiler import SourceModule\n","\n","mod2 = SourceModule(\"\"\"\n","__global__\n","void SpMV_kernel_64(double *x, double *y) \n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int R2 = blockIdx.y * blockDim.y + threadIdx.y;\n","    int R3 = blockIdx.z * blockDim.z + threadIdx.z;\n","    int NX = 128;\n","\n","\n","    double sum = 0.0;\n","    for (int bz = -1; bz < 2; bz++) {\n","        for (int by = -1; by < 2; by++) {\n","            for (int bx = -1; bx < 2; bx++) {\n","                if(R1 + bz >= 0 && R1+bz < NX && R2+by >= 0 && R2+by < NX && R3+bx >= 0 && R3+bx < NX)\n","                sum += x[(R1+bz)*NX*NX+(R2+by)*NX+(R3+bx)];\n","            }\n","        }\n","    }\n","    y[(R1) * (NX) * (NX) + (R2) * (NX) + R3] = -sum + 27.0 * x[(R1) * (NX) * (NX) + (R2) * (NX) + R3];\n","}\n","\n","\"\"\")\n","spmv_gpu_64 = mod2.get_function(\"SpMV_kernel_64\")\n","\n","mod9 = SourceModule(\"\"\"\n","__global__\n","void apxby_kernel_1d(double *x,  double *y, double *des, double *alpha, double *beta)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    des[ind] = alpha[0]*x[ind] + beta[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","apxby_gpu_1d = mod9.get_function(\"apxby_kernel_1d\")\n","\n","\n","mod7 = SourceModule(\"\"\"\n","__global__\n","void copy_kernel(double *src, double *dst)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    dst[R1] = src[R1];\n","\n","\n","}\n","\"\"\")\n","cpy_gpu = mod7.get_function(\"copy_kernel\")\n","\n","\n","mod8 = SourceModule(\"\"\"\n","__global__ void Dot_Prod(double *x, double *y, double *g_odata) {\n"," __shared__ double sdata[512];\n","// each thread loads one element from global to shared mem\n","unsigned int tid = threadIdx.x;\n","unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n","sdata[tid] = x[i]*y[i];\n","__syncthreads();\n","// do reduction in shared mem\n","for(unsigned int s=1; s < blockDim.x; s *= 2) {\n","if (tid % (2*s) == 0) {\n","sdata[tid] += sdata[tid + s];\n","}\n","__syncthreads();\n","}\n","// write result for this block to global mem\n","if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n","}\n","\n","\n","\"\"\")\n","mod10 = SourceModule(\"\"\"\n","__global__ void reduce0(double *g_in, double *g_odata) {\n"," __shared__ double sdata[512];\n","// each thread loads one element from global to shared mem\n","unsigned int tid = threadIdx.x;\n","unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n","sdata[tid] = g_in[i];\n","__syncthreads();\n","// do reduction in shared mem\n","for(unsigned int s=1; s < blockDim.x; s *= 2) {\n","if (tid % (2*s) == 0) {\n","sdata[tid] += sdata[tid + s];\n","}\n","__syncthreads();\n","}\n","// write result for this block to global mem\n","if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n","}\n","\"\"\")\n","partial_dot = mod8.get_function(\"Dot_Prod\")\n","partial_red = mod10.get_function(\"reduce0\")\n","\n","def cal_dpdt(a_gpu,b_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer1,cpu_buffer2):\n","    '''\n","    ans = (a,b)/(b,b)\n","    '''\n","    partial_dot(a_gpu,b_gpu,gpu_buffer1,block=(512,1,1),grid=(4096,1,1))\n","    partial_red(gpu_buffer1,gpu_buffer2,block=(512,1,1),grid=(8,1,1))\n","    \n","    cuda.memcpy_dtoh(cpu_buffer1,gpu_buffer2)\n","    cpu_buffer2[0]= np.sum(cpu_buffer1)\n","    \n","    partial_dot(b_gpu,b_gpu,gpu_buffer1,block=(512,1,1),grid=(4096,1,1))\n","    partial_red(gpu_buffer1,gpu_buffer2,block=(512,1,1),grid=(8,1,1))\n","    cuda.memcpy_dtoh(cpu_buffer1,gpu_buffer2)\n","    cpu_buffer2[1]= np.sum(cpu_buffer1)\n","    \n","    return cpu_buffer2[0]/cpu_buffer2[1]\n","\n","mod11 = SourceModule(\"\"\"\n","__global__\n","void plus_alpha_vector(double *x,  double *y, double *alpha)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    x[ind] = x[ind] + alpha[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","mod12 = SourceModule(\"\"\"\n","__global__\n","void subtract_alpha_vector(double *x,  double *y, double *alpha)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    x[ind] = x[ind] - alpha[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","sub_alpha_gpu = mod12.get_function(\"subtract_alpha_vector\")\n","\n","plus_alpha_gpu = mod11.get_function(\"plus_alpha_vector\")\n","\n","\n","def gpu_minres_v2(x0,b,maxit):\n","    '''\n","    gpu acceleration of MINRES algorithm\n","    x0 ,b: numpy.float64 arrays of initial guess and coefficient vector\n","    maxit: maximum number of iterations\n","    '''   \n","    alloctime = 0.0\n","    cpytime = 0.0\n","    kerneltime=0.0\n","    \n","    #event1 = cuda.Event()\n","    #event2 = cuda.Event()\n","    #event3 = cuda.Event()\n","    #event4 = cuda.Event()\n","    #event5 = cuda.Event()\n","    #event6 = cuda.Event()\n","\n","\n","\n","    #event1.record()\n","    numpytime = 0.0\n","    gputime = 0.0\n","    \n","    time1 = time.perf_counter()\n","    \n","    t1 = time.perf_counter()\n","\n","    #allocating memory\n","    #ans=np.zeros_like(x0).astype(np.float64)\n","    x=np.zeros_like(x0).astype(np.float64)\n","    r=np.zeros_like(x0).astype(np.float64)\n","\n","\n","    cst_one=np.array([1.0]).astype(np.float64)\n","    cst_neone=np.array([-1.0]).astype(np.float64)\n","    \n","    #alpha=np.array([1.0]).astype(np.float64)\n","    #beta1=np.array([1.0]).astype(np.float64)\n","    #beta2=np.array([1.0]).astype(np.float64)\n","    \n","    cpu_buffer_1=np.zeros(8).astype(np.float64)\n","    cpu_buffer_2f=np.zeros(2).astype(np.float64)\n","    cpu_buffer_3=np.zeros(1).astype(np.float64)\n","\n","    numpytime = numpytime + time.perf_counter()-t1\n","    print(numpytime)\n","    \n","    t2 = time.perf_counter()\n","    \n","    x0_gpu = cuda.mem_alloc(x0.nbytes)\n","    x_gpu = cuda.mem_alloc(x0.nbytes)\n","    b_gpu = cuda.mem_alloc(x0.nbytes)\n","    r_gpu = cuda.mem_alloc(x0.nbytes)\n","    p0_gpu = cuda.mem_alloc(x0.nbytes)\n","    p1_gpu = cuda.mem_alloc(x0.nbytes)\n","    p2_gpu = cuda.mem_alloc(x0.nbytes)\n","\n","    \n","    s0_gpu = cuda.mem_alloc(x0.nbytes)\n","    s1_gpu = cuda.mem_alloc(x0.nbytes)\n","    s2_gpu = cuda.mem_alloc(x0.nbytes)\n","\n","    \n","    one_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    neone_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    \n","    alpha_gpu = cuda.mem_alloc(8)\n","    beta1_gpu = cuda.mem_alloc(8)\n","    beta2_gpu = cuda.mem_alloc(8)\n","\n","    \n","    gpu_buffer1 = cuda.mem_alloc(int(x0.nbytes/512))\n","    gpu_buffer2 = cuda.mem_alloc(int(x0.nbytes/(512*512)))\n","    \n","    temp = cuda.mem_alloc(x0.nbytes)\n","    \n","    gputime = gputime+ time.perf_counter()-t2\n","    print(gputime)\n","    \n","    #event2.record()\n","    #event2.synchronize()\n","    #alloctime = alloctime + event2.time_since(event1)\n","    \n","    \n","    #print(\"allocating completed\")\n","    \n","    #event3.record()\n","\n","    alloctime = alloctime + time.perf_counter()-time1\n","    time2 = time.perf_counter()\n","    #copy data\n","    cuda.memcpy_htod(x0_gpu, x0)\n","    cuda.memcpy_htod(b_gpu, b)\n","\n","    cuda.memcpy_htod(one_gpu, cst_one)\n","    cuda.memcpy_htod(neone_gpu, cst_neone)\n","    \n","    cpytime = cpytime + time.perf_counter()-time2\n","    \n","    #event4.record()\n","    #event4.synchronize()\n","    #cpytime = cpytime + event4.time_since(event3)\n","\n","    #print(\"memory copy completed, begin kernel computing\")\n","    \n","    #event5.record()\n","    #x = np.array(x0)\n","    time3 = time.perf_counter()\n","    \n","    cpy_gpu(x0_gpu,x_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #r = b - A @ x0\n","    spmv_gpu_64(x0_gpu,temp,block=(8,8,8), grid=(16,16,16))\n","    \n","    apxby_gpu_1d(\n","        b_gpu,temp,r_gpu,one_gpu,neone_gpu,\n","        block=(512,1,1), grid=(16*16*16,1,1))\n","    \n","    #p0 = np.array(r)\n","    cpy_gpu(r_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s0 = A @ p0\n","    spmv_gpu_64(p0_gpu,s0_gpu,block=(8,8,8), grid=(16,16,16))\n","    \n","    #p1 = np.array(p0)\n","    cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s1 = np.array(s0)\n","    cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #print(\"pre-loop completed, begin iters...\")\n","    \n","    #event6.record()\n","    #event6.synchronize()\n","    #kerneltime = kerneltime + event6.time_since(event5)\n","    \n","    kerneltime =  kerneltime + time.perf_counter()- time3\n","    \n","    for iter in range(1,maxit):\n","        \n","        time5 = time.perf_counter()\n","        #exec(f'eventa{iter}=cuda.Event()')\n","        #exec(f'eventb{iter} = cuda.Event()')\n","\n","        #event7 = cuda.Event()\n","        #event8 = cuda.Event()\n","        \n","        #exec(f'eventa{iter}.record()')\n","    \n","        #p2 = np.ndarray.copy(p1)\n","        cpy_gpu(p1_gpu,p2_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #p1 = np.ndarray.copy(p0)\n","        cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #s2 = np.ndarray.copy(s1)\n","        cpy_gpu(s1_gpu,s2_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #s1 = np.ndarray.copy(s0)\n","        cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","\n","        #alpha = np.dot(r,s1)/np.dot(s1,s1)\n","        cpu_buffer_3[0] = cal_dpdt(r_gpu,s1_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","        cuda.memcpy_htod(alpha_gpu, cpu_buffer_3)\n","\n","        #x = x + alpha * p1\n","        plus_alpha_gpu(x_gpu,p1_gpu,alpha_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","        #r = r - alpha * s1\n","        sub_alpha_gpu(r_gpu,s1_gpu,alpha_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","\n","        #p0 = np.ndarray.copy(s1)\n","        cpy_gpu(s1_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","\n","        #s0 = A @ s1\n","        spmv_gpu_64(s1_gpu,s0_gpu,block=(8,8,8), grid=(16,16,16))\n","\n","        #beta1 = np.dot(s0,s1)/np.dot(s1,s1)\n","        cpu_buffer_3[0] = cal_dpdt(s0_gpu,s1_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","        cuda.memcpy_htod(beta1_gpu, cpu_buffer_3)\n","\n","        #p0 = p0 - beta1* p1\n","        sub_alpha_gpu(p0_gpu,p1_gpu,beta1_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","\n","        #s0 = s0 - beta1* s1\n","        sub_alpha_gpu(s0_gpu,s1_gpu,beta1_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","        if iter>1:\n","\n","                #beta2 = np.dot(s0,s2)/np.dot(s2,s2)\n","                cpu_buffer_3[0] = cal_dpdt(s0_gpu,s2_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","                cuda.memcpy_htod(beta2_gpu, cpu_buffer_3)\n","\n","                #p0 = p0 - beta2* p2\n","                sub_alpha_gpu(p0_gpu,p2_gpu,beta2_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","                #s0 = s0 - beta2* s2\n","                sub_alpha_gpu(s0_gpu,s2_gpu,beta2_gpu,block=(512,1,1),grid=(4096,1,1))\n","                \n","        kerneltime = kerneltime + time.perf_counter()-time5       \n","\n","        #event8.record()\n","        #event8.synchronize()\n","        #kerneltime = kerneltime + event8.time_since(event7)\n","\n","        #exec(f'eventb{iter}.record()')\n","        #exec(f'eventb{iter}.synchronize()')\n","        #exec(f'kerneltime=kerneltime + eventb{iter}.time_since(eventa{iter})')\n","\n","\n","\n","    \n","    \n","    #print(\"calculation completed, writing back...\")\n","    #event9 = cuda.Event()\n","    #event10=cuda.Event()\n","    #event9.record()\n","    \n","    time6=time.perf_counter()\n","    \n","    cuda.memcpy_dtoh(x,x_gpu)\n","    cuda.memcpy_dtoh(r,r_gpu)\n","    \n","    cpytime == cpytime + time.perf_counter()-time6\n","    \n","    #event10.record()\n","    #event10.synchronize()\n","    #cpytime = cpytime + event10.time_since(event9)\n","    #print(\"finished\")\n","    return x,r, alloctime,cpytime,kerneltime\n","\n","\n","x_exact = np.ones(128*128*128).astype(np.float64)\n","x0 = np.zeros(128*128*128).astype(np.float64)\n","b = np.random.random(128*128*128).astype(np.float64)\n","\n","spmv_gpu_64(cuda.In(x_exact),cuda.InOut(b),block=(8,8,8),grid=(16,16,16))\n","\n","st = time.perf_counter()\n","[x,r,t1,t2,t3]= gpu_minres_v2(x0,b,50)\n","print(t1,t2,t3)\n","sp = (time.perf_counter()-st)\n","\n","relative_error = np.sqrt(np.sum(np.square(x-x_exact)))/np.sqrt(np.sum(np.square(x_exact)))\n","residue = np.sqrt(np.sum(np.square(r)))\n","\n","print(\"relative error={}, residue={}\".format(relative_error,residue))\n","print(\"elapsed time={}\".format(sp))\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Testing time of multiple part of program(cuda):"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T09:56:52.335188Z","iopub.status.busy":"2023-01-18T09:56:52.334817Z","iopub.status.idle":"2023-01-18T09:56:52.628673Z","shell.execute_reply":"2023-01-18T09:56:52.627519Z","shell.execute_reply.started":"2023-01-18T09:56:52.335156Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["relative error=0.45699109371422114, residue=12.604018126016776\n","elapsed time=0.18545212499884656\n"]}],"source":["import pycuda.autoinit\n","import pycuda.driver as cuda\n","import numpy as np\n","#import time\n","#import timeit\n","from pycuda.compiler import SourceModule\n","\n","mod2 = SourceModule(\"\"\"\n","__global__\n","void SpMV_kernel_64(double *x, double *y) \n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int R2 = blockIdx.y * blockDim.y + threadIdx.y;\n","    int R3 = blockIdx.z * blockDim.z + threadIdx.z;\n","    int NX = 128;\n","\n","\n","    double sum = 0.0;\n","    for (int bz = -1; bz < 2; bz++) {\n","        for (int by = -1; by < 2; by++) {\n","            for (int bx = -1; bx < 2; bx++) {\n","                if(R1 + bz >= 0 && R1+bz < NX && R2+by >= 0 && R2+by < NX && R3+bx >= 0 && R3+bx < NX)\n","                sum += x[(R1+bz)*NX*NX+(R2+by)*NX+(R3+bx)];\n","            }\n","        }\n","    }\n","    y[(R1) * (NX) * (NX) + (R2) * (NX) + R3] = -sum + 27.0 * x[(R1) * (NX) * (NX) + (R2) * (NX) + R3];\n","}\n","\n","\"\"\")\n","spmv_gpu_64 = mod2.get_function(\"SpMV_kernel_64\")\n","\n","mod9 = SourceModule(\"\"\"\n","__global__\n","void apxby_kernel_1d(double *x,  double *y, double *des, double *alpha, double *beta)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    des[ind] = alpha[0]*x[ind] + beta[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","apxby_gpu_1d = mod9.get_function(\"apxby_kernel_1d\")\n","\n","\n","mod7 = SourceModule(\"\"\"\n","__global__\n","void copy_kernel(double *src, double *dst)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    dst[R1] = src[R1];\n","\n","\n","}\n","\"\"\")\n","cpy_gpu = mod7.get_function(\"copy_kernel\")\n","\n","\n","mod8 = SourceModule(\"\"\"\n","__global__ void Dot_Prod(double *x, double *y, double *g_odata) {\n"," __shared__ double sdata[512];\n","// each thread loads one element from global to shared mem\n","unsigned int tid = threadIdx.x;\n","unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n","sdata[tid] = x[i]*y[i];\n","__syncthreads();\n","// do reduction in shared mem\n","for(unsigned int s=1; s < blockDim.x; s *= 2) {\n","if (tid % (2*s) == 0) {\n","sdata[tid] += sdata[tid + s];\n","}\n","__syncthreads();\n","}\n","// write result for this block to global mem\n","if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n","}\n","\n","\n","\"\"\")\n","mod10 = SourceModule(\"\"\"\n","__global__ void reduce0(double *g_in, double *g_odata) {\n"," __shared__ double sdata[512];\n","// each thread loads one element from global to shared mem\n","unsigned int tid = threadIdx.x;\n","unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n","sdata[tid] = g_in[i];\n","__syncthreads();\n","// do reduction in shared mem\n","for(unsigned int s=1; s < blockDim.x; s *= 2) {\n","if (tid % (2*s) == 0) {\n","sdata[tid] += sdata[tid + s];\n","}\n","__syncthreads();\n","}\n","// write result for this block to global mem\n","if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n","}\n","\"\"\")\n","partial_dot = mod8.get_function(\"Dot_Prod\")\n","partial_red = mod10.get_function(\"reduce0\")\n","\n","def cal_dpdt(a_gpu,b_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer1,cpu_buffer2):\n","    '''\n","    ans = (a,b)/(b,b)\n","    '''\n","    partial_dot(a_gpu,b_gpu,gpu_buffer1,block=(512,1,1),grid=(4096,1,1))\n","    partial_red(gpu_buffer1,gpu_buffer2,block=(512,1,1),grid=(8,1,1))\n","    \n","    cuda.memcpy_dtoh(cpu_buffer1,gpu_buffer2)\n","    cpu_buffer2[0]= np.sum(cpu_buffer1)\n","    \n","    partial_dot(b_gpu,b_gpu,gpu_buffer1,block=(512,1,1),grid=(4096,1,1))\n","    partial_red(gpu_buffer1,gpu_buffer2,block=(512,1,1),grid=(8,1,1))\n","    cuda.memcpy_dtoh(cpu_buffer1,gpu_buffer2)\n","    cpu_buffer2[1]= np.sum(cpu_buffer1)\n","    \n","    return cpu_buffer2[0]/cpu_buffer2[1]\n","\n","mod11 = SourceModule(\"\"\"\n","__global__\n","void plus_alpha_vector(double *x,  double *y, double *alpha)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    x[ind] = x[ind] + alpha[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","mod12 = SourceModule(\"\"\"\n","__global__\n","void subtract_alpha_vector(double *x,  double *y, double *alpha)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    x[ind] = x[ind] - alpha[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","sub_alpha_gpu = mod12.get_function(\"subtract_alpha_vector\")\n","\n","plus_alpha_gpu = mod11.get_function(\"plus_alpha_vector\")\n","\n","\n","def gpu_minres_v2(x0,b,maxit,x,r):\n","    '''\n","    gpu acceleration of MINRES algorithm\n","    x0 ,b: numpy.float64 arrays of initial guess and coefficient vector\n","    maxit: maximum number of iterations\n","    '''   \n","    \n","    #allocating memory\n","    #ans=np.zeros_like(x0).astype(np.float64)\n","    #x=np.zeros_like(x0).astype(np.float64)\n","    #r=np.zeros_like(x0).astype(np.float64)\n","\n","\n","    cst_one=np.array([1.0]).astype(np.float64)\n","    cst_neone=np.array([-1.0]).astype(np.float64)\n","    \n","    alpha=np.array([1.0]).astype(np.float64)\n","    beta1=np.array([1.0]).astype(np.float64)\n","    beta2=np.array([1.0]).astype(np.float64)\n","\n","\n","\n","    \n","    x0_gpu = cuda.mem_alloc(x0.nbytes)\n","    x_gpu = cuda.mem_alloc(x0.nbytes)\n","    b_gpu = cuda.mem_alloc(x0.nbytes)\n","    r_gpu = cuda.mem_alloc(x0.nbytes)\n","    p0_gpu = cuda.mem_alloc(x0.nbytes)\n","    p1_gpu = cuda.mem_alloc(x0.nbytes)\n","    p2_gpu = cuda.mem_alloc(x0.nbytes)\n","\n","    \n","    s0_gpu = cuda.mem_alloc(x0.nbytes)\n","    s1_gpu = cuda.mem_alloc(x0.nbytes)\n","    s2_gpu = cuda.mem_alloc(x0.nbytes)\n","\n","    \n","    one_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    neone_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    \n","    alpha_gpu = cuda.mem_alloc(alpha.nbytes)\n","    beta1_gpu = cuda.mem_alloc(beta1.nbytes)\n","    beta2_gpu = cuda.mem_alloc(beta2.nbytes)\n","\n","    \n","    gpu_buffer1 = cuda.mem_alloc(int(x0.nbytes/512))\n","    gpu_buffer2 = cuda.mem_alloc(int(x0.nbytes/(512*512)))\n","    \n","    cpu_buffer_1=np.zeros(8).astype(np.float64)\n","    cpu_buffer_2f=np.zeros(2).astype(np.float64)\n","    cpu_buffer_3=np.zeros(1).astype(np.float64)\n","\n","\n","    \n","    temp = cuda.mem_alloc(x0.nbytes)\n","    \n","    #print(\"allocating completed\")\n","    \n","    #copy data\n","    cuda.memcpy_htod(x0_gpu, x0)\n","    cuda.memcpy_htod(b_gpu, b)\n","\n","    cuda.memcpy_htod(one_gpu, cst_one)\n","    cuda.memcpy_htod(neone_gpu, cst_neone)\n","    \n","    #print(\"memory copy completed, begin kernel computing\")\n","\n","    #x = np.array(x0)\n","    cpy_gpu(x0_gpu,x_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #r = b - A @ x0\n","    spmv_gpu_64(x0_gpu,temp,block=(4,8,8), grid=(32,16,16))\n","    \n","    apxby_gpu_1d(\n","        b_gpu,temp,r_gpu,one_gpu,neone_gpu,\n","        block=(512,1,1), grid=(16*16*16,1,1))\n","    \n","    #p0 = np.array(r)\n","    cpy_gpu(r_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s0 = A @ p0\n","    spmv_gpu_64(p0_gpu,s0_gpu,block=(4,8,8), grid=(32,16,16))\n","    \n","    #p1 = np.array(p0)\n","    cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s1 = np.array(s0)\n","    cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #print(\"pre-loop completed, begin iters...\")\n","    \n","    for iter in range(1,maxit):\n","    \n","        #p2 = np.ndarray.copy(p1)\n","        cpy_gpu(p1_gpu,p2_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #p1 = np.ndarray.copy(p0)\n","        cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #s2 = np.ndarray.copy(s1)\n","        cpy_gpu(s1_gpu,s2_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #s1 = np.ndarray.copy(s0)\n","        cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","\n","        #alpha = np.dot(r,s1)/np.dot(s1,s1)\n","        cpu_buffer_3[0] = cal_dpdt(r_gpu,s1_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","        cuda.memcpy_htod(alpha_gpu, cpu_buffer_3)\n","\n","        #x = x + alpha * p1\n","        plus_alpha_gpu(x_gpu,p1_gpu,alpha_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","        #r = r - alpha * s1\n","        sub_alpha_gpu(r_gpu,s1_gpu,alpha_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","\n","        #p0 = np.ndarray.copy(s1)\n","        cpy_gpu(s1_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","\n","        #s0 = A @ s1\n","        spmv_gpu_64(s1_gpu,s0_gpu,block=(4,8,8), grid=(32,16,16))\n","\n","        #beta1 = np.dot(s0,s1)/np.dot(s1,s1)\n","        cpu_buffer_3[0] = cal_dpdt(s0_gpu,s1_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","        cuda.memcpy_htod(beta1_gpu, cpu_buffer_3)\n","\n","        #p0 = p0 - beta1* p1\n","        sub_alpha_gpu(p0_gpu,p1_gpu,beta1_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","\n","        #s0 = s0 - beta1* s1\n","        sub_alpha_gpu(s0_gpu,s1_gpu,beta1_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","        if iter>1:\n","\n","                #beta2 = np.dot(s0,s2)/np.dot(s2,s2)\n","                cpu_buffer_3[0] = cal_dpdt(s0_gpu,s2_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","                cuda.memcpy_htod(beta2_gpu, cpu_buffer_3)\n","\n","                #p0 = p0 - beta2* p2\n","                sub_alpha_gpu(p0_gpu,p2_gpu,beta2_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","                #s0 = s0 - beta2* s2\n","                sub_alpha_gpu(s0_gpu,s2_gpu,beta2_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","    \n","    \n","    #print(\"calculation completed, writing back...\")\n","    \n","    cuda.memcpy_dtoh(x,x_gpu)\n","    cuda.memcpy_dtoh(r,r_gpu)\n","\n","    #print(\"finished\")\n","    return \n","\n","\n","x_exact = np.ones(128*128*128).astype(np.float64)\n","\n","x = np.ones(128*128*128).astype(np.float64)\n","r = np.ones(128*128*128).astype(np.float64)\n","\n","x0 = np.zeros(128*128*128).astype(np.float64)\n","b = np.random.random(128*128*128).astype(np.float64)\n","\n","spmv_gpu_64(cuda.In(x_exact),cuda.InOut(b),block=(8,8,8),grid=(16,16,16))\n","\n","st = time.perf_counter()\n","gpu_minres_v2(x0,b,50,x,r)\n","sp = (time.perf_counter()-st)\n","\n","relative_error = np.sqrt(np.sum(np.square(x-x_exact)))/np.sqrt(np.sum(np.square(x_exact)))\n","residue = np.sqrt(np.sum(np.square(r)))\n","\n","print(\"relative error={}, residue={}\".format(relative_error,residue))\n","print(\"elapsed time={}\".format(sp))\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["mem alloc time:0.0244211630006248 cpu-gpu copy time:0.007241348000206926 kernel time: 0.1790220609982498\n","relative error=0.45699109371422114, residue=12.604018126016776\n","elapsed time=0.22552574499968614"]},{"cell_type":"markdown","metadata":{},"source":["details of alloc time:\n","numpy time: 0.013281465000545722\n","gpu time: 0.001474357000006421\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Testing specific kernel:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T14:40:42.698957Z","iopub.status.busy":"2023-01-17T14:40:42.698543Z","iopub.status.idle":"2023-01-17T14:40:43.137798Z","shell.execute_reply":"2023-01-17T14:40:43.136448Z","shell.execute_reply.started":"2023-01-17T14:40:42.698925Z"},"trusted":true},"outputs":[],"source":["\n","\n","from pycuda.compiler import SourceModule\n","mod = SourceModule(\"\"\"\n","__global__\n","void apxby_kernel_64(double *x,  double *y, double *des, double *alpha, double *beta)\n","{\n","    int NX = 128;\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int R2 = blockIdx.y * blockDim.y + threadIdx.y;\n","    int R3 = blockIdx.z * blockDim.z + threadIdx.z;\n","    \n","    \n","    int ind = (R1) * (NX) * (NX) + (R2) * (NX) + R3;\n","    des[ind] = alpha[0]*x[ind] + beta[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","apxby_gpu_64 = mod.get_function(\"apxby_kernel_64\")\n","\n","a = np.random.randn(128*128*128).astype(np.float64)\n","b = np.random.randn(128*128*128).astype(np.float64)\n","alpha = np.array([1.0]).astype(np.float64)\n","beta = np.array([2.0]).astype(np.float64)\n","dest = np.zeros_like(a).astype(np.float64)\n","\n","begin = time.perf_counter()\n","\n","apxby_gpu_64(\n","        cuda.In(a),cuda.In(b),cuda.InOut(dest),cuda.In(alpha),cuda.In(beta),\n","        block=(8,8,8), grid=(16,16,16))\n","end = time.perf_counter()\n","\n","gpu_time = end-begin\n","print(gpu_time)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T20:33:13.663735Z","iopub.status.busy":"2023-01-17T20:33:13.663380Z","iopub.status.idle":"2023-01-17T20:33:13.757324Z","shell.execute_reply":"2023-01-17T20:33:13.756174Z","shell.execute_reply.started":"2023-01-17T20:33:13.663704Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0.07263612099995953\n","0.007991972000127134\n"]}],"source":["x_exact = np.zeros(128*128*128).astype(np.float64)\n","\n","t1 = time.perf_counter()\n","A @ x_exact\n","print(time.perf_counter()-t1)\n","\n","t2 = time.perf_counter()\n","x_gpu = cuda.mem_alloc(x_exact.nbytes)\n","x2 = cuda.mem_alloc(x_exact.nbytes)\n","cuda.memcpy_htod(x_gpu,x_exact)\n","spmv_gpu_64(x2,x_gpu,block=(8,8,8), grid=(16,16,16))\n","cuda.memcpy_dtoh(x_exact,x2)\n","\n","print(time.perf_counter()-t2)\n","\n","\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Comparing CPU and GPU:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def cpu_apxby(a,b):\n","    return a*alpha[0]+b*beta[0]\n","begin = time.time()\n","c_dest = cpu_apxby(a,b)\n","end = time.time()\n","cpu_time = end - begin\n","\n","print(np.max(np.abs(c_dest-dest)))\n","print(\"gpu time: {}\".format(gpu_time))\n","print(\"cpu time: {}\".format(cpu_time))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Testing specific kernel:"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T12:36:01.843525Z","iopub.status.busy":"2023-01-18T12:36:01.842944Z","iopub.status.idle":"2023-01-18T12:36:01.887615Z","shell.execute_reply":"2023-01-18T12:36:01.885683Z","shell.execute_reply.started":"2023-01-18T12:36:01.843483Z"},"trusted":true},"outputs":[{"ename":"CompileError","evalue":"nvcc compilation of /tmp/tmp8f41ev4e/kernel.cu failed\n[command: nvcc --cubin -arch sm_60 -O3 -I/opt/conda/lib/python3.7/site-packages/pycuda/cuda kernel.cu]\n[stderr:\nnvcc fatal   : Value 'sm_60 -O3' is not defined for option 'gpu-architecture'\n]","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mCompileError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3438139925.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m }\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \"\"\",arch='sm_60 -O3')\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mspmv_gpu_64_fast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"SpMV_kernel_64\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs)\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m             \u001b[0minclude_dirs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m         )\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(source, nvcc, options, keep, no_extern_c, arch, code, cache_dir, include_dirs, target)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-I\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcompile_plain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnvcc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycuda/compiler.py\u001b[0m in \u001b[0;36mcompile_plain\u001b[0;34m(source, options, keep, nvcc, cache_dir, target)\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0mcmdline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m             \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    159\u001b[0m         )\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCompileError\u001b[0m: nvcc compilation of /tmp/tmp8f41ev4e/kernel.cu failed\n[command: nvcc --cubin -arch sm_60 -O3 -I/opt/conda/lib/python3.7/site-packages/pycuda/cuda kernel.cu]\n[stderr:\nnvcc fatal   : Value 'sm_60 -O3' is not defined for option 'gpu-architecture'\n]"]}],"source":["mod2 = SourceModule(\"\"\"\n","__global__\n","void SpMV_kernel_64(double *x, double *y) \n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int R2 = blockIdx.y * blockDim.y + threadIdx.y;\n","    int R3 = blockIdx.z * blockDim.z + threadIdx.z;\n","    int NX = 128;\n","\n","\n","    double sum = 0.0;\n","    for (int bz = -1; bz < 2; bz++) {\n","        for (int by = -1; by < 2; by++) {\n","            for (int bx = -1; bx < 2; bx++) {\n","                if(R1 + bz >= 0 && R1+bz < NX && R2+by >= 0 && R2+by < NX && R3+bx >= 0 && R3+bx < NX)\n","                sum += x[(R1+bz)*NX*NX+(R2+by)*NX+(R3+bx)];\n","            }\n","        }\n","    }\n","    y[(R1) * (NX) * (NX) + (R2) * (NX) + R3] = -sum + 27.0 * x[(R1) * (NX) * (NX) + (R2) * (NX) + R3];\n","}\n","\n","\"\"\",arch='sm_60 -O3')\n","spmv_gpu_64_fast = mod2.get_function(\"SpMV_kernel_64\")\n","e = np.random.randn(128*128*128).astype(np.float64)\n","f = np.zeros_like(e)\n","start = time.perf_counter()\n","spmv_gpu_64_fast(cuda.In(e),cuda.InOut(f),block=(8,8,8), grid=(16,16,16))\n","\n","end = time.perf_counter()\n","\n","gpu_time = end-start\n","print(gpu_time)"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T12:32:23.440538Z","iopub.status.busy":"2023-01-18T12:32:23.440036Z","iopub.status.idle":"2023-01-18T12:32:23.456157Z","shell.execute_reply":"2023-01-18T12:32:23.454850Z","shell.execute_reply.started":"2023-01-18T12:32:23.440488Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["rn\n"]}],"source":["def testspmv(block,grid):\n","    a = np.random.random(128*128*128).astype(np.float64)\n","    b = np.zeros_like(a)\n","    a_gpu = cuda.mem_alloc(a.nbytes)\n","    b_gpu = cuda.mem_alloc(b.nbytes)\n","    cuda.memcpy_htod(a_gpu,a)\n","    #t1 = time.perf_counter()\n","    %timeit spmv_gpu_64_fast(a_gpu,b_gpu,block=block,grid=grid)\n","    #t2 = time.perf_counter()\n","    #print(block, t2-t1)\n","    return\n","print(\"rn\")\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T12:32:27.084163Z","iopub.status.busy":"2023-01-18T12:32:27.083794Z","iopub.status.idle":"2023-01-18T12:33:33.182075Z","shell.execute_reply":"2023-01-18T12:33:33.181043Z","shell.execute_reply.started":"2023-01-18T12:32:27.084130Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["825 µs ± 32.2 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["testspmv((8,8,8),(16,16,16))"]},{"cell_type":"markdown","metadata":{},"source":["824 µs ± 21.4 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T08:29:26.133808Z","iopub.status.busy":"2023-01-18T08:29:26.133447Z","iopub.status.idle":"2023-01-18T08:30:32.087472Z","shell.execute_reply":"2023-01-18T08:30:32.086469Z","shell.execute_reply.started":"2023-01-18T08:29:26.133776Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["812 µs ± 17.3 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["testspmv((4,8,8),(32,16,16))"]},{"cell_type":"code","execution_count":58,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T08:31:29.091862Z","iopub.status.busy":"2023-01-18T08:31:29.090914Z","iopub.status.idle":"2023-01-18T08:32:43.699328Z","shell.execute_reply":"2023-01-18T08:32:43.698044Z","shell.execute_reply.started":"2023-01-18T08:31:29.091825Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["919 µs ± 188 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["testspmv((16,8,8),(8,16,16))"]},{"cell_type":"code","execution_count":59,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T08:33:09.766728Z","iopub.status.busy":"2023-01-18T08:33:09.766370Z","iopub.status.idle":"2023-01-18T08:34:22.934782Z","shell.execute_reply":"2023-01-18T08:34:22.933666Z","shell.execute_reply.started":"2023-01-18T08:33:09.766695Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["901 µs ± 26.7 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["testspmv((4,4,4),(32,32,32))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Making sparse matrix\\Tesing cpu:"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T20:01:32.236915Z","iopub.status.busy":"2023-01-17T20:01:32.236504Z","iopub.status.idle":"2023-01-17T20:05:42.541650Z","shell.execute_reply":"2023-01-17T20:05:42.540647Z","shell.execute_reply.started":"2023-01-17T20:01:32.236861Z"},"trusted":true},"outputs":[],"source":["from scipy.sparse import dia_matrix\n","total =128*128*128\n","N = 128\n","data = 26*np.ones(total)\n","offsets = np.array([0])\n","A = dia_matrix((data,offsets),shape=(total,total),dtype=\"float64\")\n","A = A.tolil()\n","for i in range(N):\n","    for j in range(N):\n","        for k in range(N):\n","            for bz in range(-1,2):\n","                for by in range(-1,2):\n","                    for bx in range(-1,2):\n","                        if i+bz>=0 and i+bz < N and j + by>=0 and j+by<N and k+bx>=0 and k+bx<N and bx*bx+by*by+bz*bz!=0:\n","                            A[i*N*N+ j*N+k,(i+bz)*N*N+ (j+by)*N+(k+bx)] = -1   \n","A = A.tocsr()\n","x_exact = np.ones(total,dtype='float64')\n","x0 = np.zeros(total,dtype='float64')\n","b = A @ x_exact"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T20:07:37.680779Z","iopub.status.busy":"2023-01-17T20:07:37.680165Z","iopub.status.idle":"2023-01-17T20:07:37.693859Z","shell.execute_reply":"2023-01-17T20:07:37.693149Z","shell.execute_reply.started":"2023-01-17T20:07:37.680736Z"},"trusted":true},"outputs":[],"source":["def cpu_minres(A,x0,b,maxit):\n","    x = np.array(x0)\n","    r = b - A @ x0\n","    p0 = np.array(r)\n","    s0 = A @ p0\n","    p1 = np.array(p0)\n","    s1 = np.array(s0)\n","    for iter in range(1,maxit):\n","        p2 = np.ndarray.copy(p1)\n","        p1 = np.ndarray.copy(p0)\n","        s2 = np.ndarray.copy(s1)\n","        s1 = np.ndarray.copy(s0)\n","        alpha = np.dot(r,s1)/np.dot(s1,s1)\n","        x = x + alpha * p1\n","        r = r - alpha * s1\n","        p0 = np.ndarray.copy(s1)\n","        s0 = A @ s1\n","        beta1 = np.dot(s0,s1)/np.dot(s1,s1)\n","        p0 = p0 - beta1* p1\n","        s0 = s0 - beta1* s1\n","        if iter>1:\n","            beta2 = np.dot(s0,s2)/np.dot(s2,s2)\n","            p0 = p0 - beta2* p2\n","            s0 = s0 - beta2* s2\n","        #print(\"iter{} finished!,x0={},beta1={}\".format(iter,x[0],beta1))\n","            \n","    return x, r"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T20:06:06.608815Z","iopub.status.busy":"2023-01-17T20:06:06.608472Z","iopub.status.idle":"2023-01-17T20:06:06.617091Z","shell.execute_reply":"2023-01-17T20:06:06.616028Z","shell.execute_reply.started":"2023-01-17T20:06:06.608785Z"},"trusted":true},"outputs":[{"data":{"text/plain":["<2097152x2097152 sparse matrix of type '<class 'numpy.float64'>'\n","\twith 55742968 stored elements in Compressed Sparse Row format>"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["A"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T20:07:45.914045Z","iopub.status.busy":"2023-01-17T20:07:45.913669Z","iopub.status.idle":"2023-01-17T20:07:56.498442Z","shell.execute_reply":"2023-01-17T20:07:56.494173Z","shell.execute_reply.started":"2023-01-17T20:07:45.914012Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["relative error=0.4569910937141935, residue=12.604018126018175\n","elapsed time:10.46273946762085 \n"]}],"source":["x_exact = np.ones(128*128*128).astype(np.float64)\n","b = A @ x_exact\n","x0 = np.zeros_like(x_exact).astype(np.float64)\n","st = time.time()\n","[x,r]= cpu_minres(A,x0,b,50)\n","sp = time.time()-st\n","relative_error = np.sqrt(np.sum(np.square(x-x_exact)))/np.sqrt(np.sum(np.square(x_exact)))\n","residue = np.sqrt(np.sum(np.square(r)))\n","print(\"relative error={}, residue={}\".format(relative_error,residue))\n","print(\"elapsed time:{} \".format(sp))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Testing gpu array:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["import pycuda.gpuarray as gpy\n","\n","t = np.random.random(128*128*128).astype(np.float64)\n","s = np.zeros_like(t)\n","k = np.zeros_like(t)\n","t_gpu = gpy.to_gpu(t)\n","s_gpu = gpy.to_gpu(s)\n","l = t_gpu.get()\n","z = s_gpu.get()\n","spmv_gpu_64(l,z,block=(8,8,8), grid=(16,16,16))\n","print(\"finished\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"start\")\n","mod9 = SourceModule(\"\"\"\n","__global__\n","void apxby_kernel_1d(double *x,  double *y, double *des, double *alpha, double *beta)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    des[ind] = alpha[0]*x[ind] + beta[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","apxby_gpu_1d = mod9.get_function(\"apxby_kernel_1d\")\n","\n","a = np.random.randn(128*128*128).astype(np.float64)\n","b = np.random.randn(128*128*128).astype(np.float64)\n","alpha = np.array([1.0]).astype(np.float64)\n","beta = np.array([2.0]).astype(np.float64)\n","dest = np.zeros_like(a).astype(np.float64)\n","ans =np.zeros_like(dest)\n","t1 = time.time()\n","a_gpu = cuda.mem_alloc(a.nbytes)\n","b_gpu = cuda.mem_alloc(b.nbytes)\n","alpha_gpu = cuda.mem_alloc(alpha.nbytes)\n","beta_gpu = cuda.mem_alloc(beta.nbytes)\n","dest_gpu = cuda.mem_alloc(dest.nbytes)\n","\n","cuda.memcpy_htod(a_gpu, a)\n","cuda.memcpy_htod(b_gpu, b)\n","cuda.memcpy_htod(alpha_gpu, alpha)\n","cuda.memcpy_htod(beta_gpu, beta)\n","\n","cuda.memcpy_htod(dest_gpu, dest)\n","\n","t2=time.time()\n","apxby_gpu_1d(\n","        a_gpu,b_gpu,dest_gpu,alpha_gpu,beta_gpu,\n","        block=(512,1,1), grid=(16*16*16,1,1))\n","t3=time.time()\n","cuda.memcpy_dtoh(ans,dest_gpu)\n","\n","t4 = time.time()\n","\n","print(t3-t2)\n","print(t4-t1)\n","print(np.max(np.abs(alpha[0]*a+beta[0]*b-ans)))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T14:43:10.778730Z","iopub.status.busy":"2023-01-17T14:43:10.778359Z","iopub.status.idle":"2023-01-17T14:43:10.824167Z","shell.execute_reply":"2023-01-17T14:43:10.823142Z","shell.execute_reply.started":"2023-01-17T14:43:10.778698Z"},"trusted":true},"outputs":[],"source":["mod7 = SourceModule(\"\"\"\n","__global__\n","void copy_kernel(double *src, double *dst)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    dst[R1] = src[R1];\n","\n","\n","}\n","\"\"\")\n","cpy_gpu = mod7.get_function(\"copy_kernel\")\n","a = np.random.random(128*128*128).astype(np.float64)\n","b = np.zeros_like(a)\n","cpy_gpu(cuda.In(a),cuda.InOut(b),block=(512,1,1),grid=(16*16*16,1,1))\n","print(a[0],b[0])\n"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T12:29:55.475739Z","iopub.status.busy":"2023-01-18T12:29:55.475294Z","iopub.status.idle":"2023-01-18T12:29:55.801093Z","shell.execute_reply":"2023-01-18T12:29:55.799596Z","shell.execute_reply.started":"2023-01-18T12:29:55.475700Z"},"trusted":true},"outputs":[],"source":["mod7 = SourceModule(\"\"\"\n","__global__\n","void copy_kernel(double *src, double *dst)\n","{\n","    \n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    dst[R1] = src[R1];\n","\n","\n","}\n","\"\"\"\n",",arch='sm_60')\n","cpy_gpu_1d = mod7.get_function(\"copy_kernel\")"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T12:30:04.214092Z","iopub.status.busy":"2023-01-18T12:30:04.213486Z","iopub.status.idle":"2023-01-18T12:30:04.224728Z","shell.execute_reply":"2023-01-18T12:30:04.223828Z","shell.execute_reply.started":"2023-01-18T12:30:04.214045Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["rn\n"]}],"source":["def testcpykernel(block,grid):\n","    a = np.random.random(128*128*128).astype(np.float64)\n","    b = np.zeros_like(a)\n","    a_gpu = cuda.mem_alloc(a.nbytes)\n","    b_gpu = cuda.mem_alloc(b.nbytes)\n","    cuda.memcpy_htod(a_gpu,a)\n","    t1 = time.perf_counter()\n","    %timeit cpy_gpu_1d(a_gpu,b_gpu,block=(block,1,1),grid=(grid,1,1))\n","    t2 = time.perf_counter()\n","    #print(block, t2-t1)\n","    return\n","print(\"rn\")"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T07:59:07.576561Z","iopub.status.busy":"2023-01-18T07:59:07.576126Z","iopub.status.idle":"2023-01-18T07:59:35.032740Z","shell.execute_reply":"2023-01-18T07:59:35.031701Z","shell.execute_reply.started":"2023-01-18T07:59:07.576521Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["338 µs ± 24 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel((8,8,8),(16,16,16))\n","except:\n","    raise Exception('fail')\n"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T08:02:27.975906Z","iopub.status.busy":"2023-01-18T08:02:27.975420Z","iopub.status.idle":"2023-01-18T08:02:58.749529Z","shell.execute_reply":"2023-01-18T08:02:58.748463Z","shell.execute_reply.started":"2023-01-18T08:02:27.975861Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["379 µs ± 26.2 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel((4,4,4),(32,32,32))\n","except:\n","    raise Exception('fail')"]},{"cell_type":"code","execution_count":67,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T09:22:38.233883Z","iopub.status.busy":"2023-01-18T09:22:38.233531Z","iopub.status.idle":"2023-01-18T09:22:43.469629Z","shell.execute_reply":"2023-01-18T09:22:43.468490Z","shell.execute_reply.started":"2023-01-18T09:22:38.233852Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["64.1 µs ± 6.55 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["testcpykernel(512,4096)\n"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:54:18.482872Z","iopub.status.busy":"2023-01-18T06:54:18.482418Z","iopub.status.idle":"2023-01-18T06:54:23.720791Z","shell.execute_reply":"2023-01-18T06:54:23.718988Z","shell.execute_reply.started":"2023-01-18T06:54:18.482832Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["64.2 µs ± 7.23 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(900)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:54:49.217788Z","iopub.status.busy":"2023-01-18T06:54:49.217428Z","iopub.status.idle":"2023-01-18T06:54:54.459054Z","shell.execute_reply":"2023-01-18T06:54:54.457948Z","shell.execute_reply.started":"2023-01-18T06:54:49.217756Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["64.3 µs ± 4.19 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(1024)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:55:12.182560Z","iopub.status.busy":"2023-01-18T06:55:12.182214Z","iopub.status.idle":"2023-01-18T06:55:17.408377Z","shell.execute_reply":"2023-01-18T06:55:17.407215Z","shell.execute_reply.started":"2023-01-18T06:55:12.182530Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["64.1 µs ± 6.23 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(256)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:55:30.836798Z","iopub.status.busy":"2023-01-18T06:55:30.836439Z","iopub.status.idle":"2023-01-18T06:55:36.067628Z","shell.execute_reply":"2023-01-18T06:55:36.065663Z","shell.execute_reply.started":"2023-01-18T06:55:30.836766Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["64.1 µs ± 10.1 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(128)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:55:47.873357Z","iopub.status.busy":"2023-01-18T06:55:47.872746Z","iopub.status.idle":"2023-01-18T06:55:53.121463Z","shell.execute_reply":"2023-01-18T06:55:53.120400Z","shell.execute_reply.started":"2023-01-18T06:55:47.873310Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["64.2 µs ± 7.07 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(64)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:56:02.939114Z","iopub.status.busy":"2023-01-18T06:56:02.938254Z","iopub.status.idle":"2023-01-18T06:56:12.164153Z","shell.execute_reply":"2023-01-18T06:56:12.163071Z","shell.execute_reply.started":"2023-01-18T06:56:02.939058Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["113 µs ± 3.48 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(32)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:56:22.990502Z","iopub.status.busy":"2023-01-18T06:56:22.989913Z","iopub.status.idle":"2023-01-18T06:56:41.114560Z","shell.execute_reply":"2023-01-18T06:56:41.113486Z","shell.execute_reply.started":"2023-01-18T06:56:22.990465Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["223 µs ± 2.18 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(16)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:59:44.622105Z","iopub.status.busy":"2023-01-18T06:59:44.621712Z","iopub.status.idle":"2023-01-18T07:00:20.623820Z","shell.execute_reply":"2023-01-18T07:00:20.622084Z","shell.execute_reply.started":"2023-01-18T06:59:44.622067Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["443 µs ± 1.34 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(8)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T07:02:37.408774Z","iopub.status.busy":"2023-01-18T07:02:37.407897Z","iopub.status.idle":"2023-01-18T07:03:49.153657Z","shell.execute_reply":"2023-01-18T07:03:49.152584Z","shell.execute_reply.started":"2023-01-18T07:02:37.408725Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["884 µs ± 104 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(4)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T07:04:42.152246Z","iopub.status.busy":"2023-01-18T07:04:42.151876Z","iopub.status.idle":"2023-01-18T07:07:05.381666Z","shell.execute_reply":"2023-01-18T07:07:05.380530Z","shell.execute_reply.started":"2023-01-18T07:04:42.152215Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["1.77 ms ± 1.26 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["try:\n","    testcpykernel(2)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T07:01:52.222906Z","iopub.status.busy":"2023-01-18T07:01:52.222306Z","iopub.status.idle":"2023-01-18T07:02:20.918211Z","shell.execute_reply":"2023-01-18T07:02:20.917095Z","shell.execute_reply.started":"2023-01-18T07:01:52.222863Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["3.53 ms ± 21 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"]}],"source":["try:\n","    testcpykernel(1)\n","except:\n","    raise Exception(\"can't\")"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T06:59:09.771180Z","iopub.status.busy":"2023-01-18T06:59:09.770800Z","iopub.status.idle":"2023-01-18T06:59:09.827231Z","shell.execute_reply":"2023-01-18T06:59:09.825776Z","shell.execute_reply.started":"2023-01-18T06:59:09.771148Z"},"trusted":true},"outputs":[{"ename":"Exception","evalue":"can't","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mLogicError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3022218385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtestcpykernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/647268163.py\u001b[0m in \u001b[0;36mtestcpykernel\u001b[0;34m(block)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cpy_gpu(a_gpu,b_gpu,block=(block,1,1),grid=(int(128*128*128/block),1,1))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1179\u001b[0m                 \u001b[0mnumber\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycuda/driver.py\u001b[0m in \u001b[0;36mfunction_call\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_block_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m         \u001b[0mhandlers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg_buf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_build_arg_buf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mLogicError\u001b[0m: cuFuncSetBlockShape failed: invalid argument","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/3022218385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtestcpykernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"can't\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mException\u001b[0m: can't"]}],"source":["try:\n","    testcpykernel(1025)\n","except:\n","    raise Exception(\"can't\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Tru precompile option:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T14:55:11.447590Z","iopub.status.busy":"2023-01-17T14:55:11.447226Z","iopub.status.idle":"2023-01-17T14:55:11.465727Z","shell.execute_reply":"2023-01-17T14:55:11.464198Z","shell.execute_reply.started":"2023-01-17T14:55:11.447560Z"},"trusted":true},"outputs":[],"source":["cpy_gpu.prepare('P')\n","a_gpu=cuda.mem_alloc(a.nbytes)\n","b_gpu=cuda.mem_alloc(a.nbytes)\n","grid=16*16*16\n","block=512\n","cpy_gpu.prepared_call(grid,block,(a_gpu,b_gpu))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T14:54:18.693536Z","iopub.status.busy":"2023-01-17T14:54:18.693076Z","iopub.status.idle":"2023-01-17T14:54:18.749706Z","shell.execute_reply":"2023-01-17T14:54:18.748865Z","shell.execute_reply.started":"2023-01-17T14:54:18.693495Z"},"trusted":true},"outputs":[],"source":["?cpy_gpu.prepared_call"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["Partial results:"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def gpu_minres_short(x0,b):\n","    #x = np.array(x0)\n","    #r = b - A @ x0\n","    #p0 = np.array(r)\n","    #s0 = A @ p0\n","    #p1 = np.array(p0)\n","    #s1 = np.array(s0)\n","    \n","    ans=np.zeros_like(x0).astype(np.float64)\n","    cst_one=np.array([1.0]).astype(np.float64)\n","    cst_neone=np.array([-1.0]).astype(np.float64)\n","    \n","    x0_gpu = cuda.mem_alloc(x0.nbytes)\n","    x_gpu = cuda.mem_alloc(x0.nbytes)\n","    b_gpu = cuda.mem_alloc(x0.nbytes)\n","    r_gpu = cuda.mem_alloc(x0.nbytes)\n","    p0_gpu = cuda.mem_alloc(x0.nbytes)\n","    s0_gpu = cuda.mem_alloc(x0.nbytes)\n","    p1_gpu = cuda.mem_alloc(x0.nbytes)\n","    s1_gpu = cuda.mem_alloc(x0.nbytes)\n","    \n","    one_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    neone_gpu = cuda.mem_alloc(cst_one.nbytes)\n","\n","\n","    \n","    temp = cuda.mem_alloc(x0.nbytes)\n","    \n","    print(\"allocating completed\")\n","    \n","    cuda.memcpy_htod(x0_gpu, x0)\n","    cuda.memcpy_htod(b_gpu, b)\n","\n","    cuda.memcpy_htod(one_gpu, cst_one)\n","    cuda.memcpy_htod(neone_gpu, cst_neone)\n","    \n","    print(\"memory copy completed, begin kernel computing\")\n","\n","    \n","    cpy_gpu(x0_gpu,x_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    spmv_gpu_64(x0_gpu,temp,block=(8,8,8), grid=(16,16,16))\n","    apxby_gpu_1d(\n","        b_gpu,temp,r_gpu,one_gpu,neone_gpu,\n","        block=(512,1,1), grid=(16*16*16,1,1))\n","    cpy_gpu(r_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    spmv_gpu_64(p0_gpu,s0_gpu,block=(8,8,8), grid=(16,16,16))\n","    cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    print(\"kernel computing completed, begin writing back\")\n","\n","    cuda.memcpy_dtoh(ans,s1_gpu)\n","    \n","    print(\"finished\")\n","    return ans\n","\n","\n","\n","\n","\n","\n","    \n","   "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["p = gpu_minres_short(x0,b)\n","print(p[0],p[1],p[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x_exact = np.ones(128*128*128).astype(np.float64)\n","b = A @ x_exact\n","x0 = np.zeros_like(x_exact).astype(np.float64)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def cpu_minres_short(A,x0,b):\n","    x = np.array(x0)\n","    r = b - A @ x0\n","    p0 = np.array(r)\n","    s0 = A @ p0\n","    p1 = np.array(p0)\n","    s1 = np.array(s0)\n","    return s1"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["t = cpu_minres_short(A,x0,b)\n","print(t[0],t[1],t[2])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mod5 = SourceModule(\"\"\"\n","__global__ void DotProd(double* x, double* y, double* scalar){\n","    extern __shared__ double cache[512];\n","\n","    int tid = threadIdx.x+ blockIdx.x*blockDim.x;\n","    int cacheIndex = threadIdx.x;\n","\n","    double temp=0;\n","    while (tid<128*128*128){\n","        temp+=x[tid]*y[tid];\n","        tid +=blockDim.x*gridDim.x; \n","    }\n","    cache[cacheIndex]=temp;\n","    __syncthreads();\n","\n","    int i=blockDim.x/2;\n","    while(i!=0){\n","        if (cacheIndex<i)\n","            cache[cacheIndex]+=cache[cacheIndex+i];\n","        __syncthreads();\n","        i/=2;\n","    }\n","    if(cacheIndex==0)\n","        scalar[blockIdx.x]=cache[cacheIndex];\n","}\n","\"\"\")\n","dot_prod_gpu = mod5.get_function(\"DotProd\")\n","a = np.random.randn(128*128*128).astype(np.float64)\n","b = np.random.randn(128*128*128).astype(np.float64)\n","c = np.array([0.]).astype(np.float64)\n","dot_prod_gpu(cuda.In(a),cuda.In(b),cuda.InOut(c),block=(512,1,1),grid=(4096,1,1))\n","print(np.dot(a,b),c)\n"]},{"cell_type":"code","execution_count":85,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2023-01-18T09:57:34.887237Z","iopub.status.busy":"2023-01-18T09:57:34.886867Z","iopub.status.idle":"2023-01-18T09:57:41.213555Z","shell.execute_reply":"2023-01-18T09:57:41.211936Z","shell.execute_reply.started":"2023-01-18T09:57:34.887204Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/2256299037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'timeit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'partial_dot(cuda.In(a),cuda.In(b),cuda.InOut(c),block=(512,1,1),grid=(4096,1,1))'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0mpartial_red\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInOut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0mansw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2415\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2416\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2417\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m         \u001b[0mall_runs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m         \u001b[0mbest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m         \u001b[0mworst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_runs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/timeit.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(self, repeat, number)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m             \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    167\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycuda/driver.py\u001b[0m in \u001b[0;36mfunction_call\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 484\u001b[0;31m             \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtexref\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtexrefs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pycuda/driver.py\u001b[0m in \u001b[0;36mpre_call\u001b[0;34m(self, stream)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0mmemcpy_htod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_alloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0mmemcpy_htod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_alloc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["mod8 = SourceModule(\"\"\"\n","__global__ void Dot_Prod(double *x, double *y, double *g_odata) {\n"," __shared__ double sdata[1024];\n","// each thread loads one element from global to shared mem\n","unsigned int tid = threadIdx.x;\n","unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n","sdata[tid] = x[i]*y[i];\n","__syncthreads();\n","// do reduction in shared mem\n","for(unsigned int s=1; s < blockDim.x; s *= 2) {\n","if (tid % (2*s) == 0) {\n","sdata[tid] += sdata[tid + s];\n","}\n","__syncthreads();\n","}\n","// write result for this block to global mem\n","if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n","}\n","\n","\n","\"\"\")\n","mod10 = SourceModule(\"\"\"\n","__global__ void reduce0(double *g_in, double *g_odata) {\n"," __shared__ double sdata[1024];\n","// each thread loads one element from global to shared mem\n","unsigned int tid = threadIdx.x;\n","unsigned int i = blockIdx.x*blockDim.x + threadIdx.x;\n","sdata[tid] = g_in[i];\n","__syncthreads();\n","// do reduction in shared mem\n","for(unsigned int s=1; s < blockDim.x; s *= 2) {\n","if (tid % (2*s) == 0) {\n","sdata[tid] += sdata[tid + s];\n","}\n","__syncthreads();\n","}\n","// write result for this block to global mem\n","if (tid == 0) g_odata[blockIdx.x] = sdata[0];\n","}\n","\"\"\")\n","partial_dot = mod8.get_function(\"Dot_Prod\")\n","partial_red = mod10.get_function(\"reduce0\")\n","\n","a = np.random.random(128*128*128).astype(np.float64)\n","b = np.random.random(128*128*128).astype(np.float64)\n","c = np.zeros(32*128).astype(np.float64)\n","d = np.zeros(8).astype(np.float64)\n","%timeit partial_dot(cuda.In(a),cuda.In(b),cuda.InOut(c),block=(512,1,1),grid=(4096,1,1))\n","partial_red(cuda.In(c),cuda.InOut(d),block=(512,1,1),grid=(8,1,1))\n","answ = np.sum(d)\n","real_answ = np.dot(a,b)\n","#print(answ,real_answ)\n","print(a,b,real_answ,answ)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def gpu_reduce(a_gpu,b_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer1,cpu_buffer2,gpu_buff):\n","    partial_dot(a_gpu,b_gpu,gpu_buffer1,block=(512,1,1),grid=(4096,1,1))\n","    partial_red(gpu_buffer1,gpu_buffer2,block=(512,1,1),grid=(8,1,1))\n","    cuda.memcpy_dtoh(cpu_buffer1,gpu_buffer2)\n","    cpu_buffer2[0]= np.sum(cpu_buffer1)\n","    cuda.memcpy_htod(gpu_buff,cpu_buffer2)\n","    return\n","\n","\n","\n","    "]},{"cell_type":"code","execution_count":71,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T09:27:16.582970Z","iopub.status.busy":"2023-01-18T09:27:16.582291Z","iopub.status.idle":"2023-01-18T09:27:16.590301Z","shell.execute_reply":"2023-01-18T09:27:16.589346Z","shell.execute_reply.started":"2023-01-18T09:27:16.582936Z"},"trusted":true},"outputs":[],"source":["def cal_dpdt_fast(a_gpu,b_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer1,cpu_buffer2):\n","    '''\n","    ans = (a,b)/(b,b)\n","    '''\n","    partial_dot(a_gpu,b_gpu,gpu_buffer1,block=(1024,1,1),grid=(2048,1,1))\n","    partial_red(gpu_buffer1,gpu_buffer2,block=(1024,1,1),grid=(2,1,1))\n","    \n","    cuda.memcpy_dtoh(cpu_buffer1,gpu_buffer2)\n","    cpu_buffer2[0]= np.sum(cpu_buffer1)\n","    \n","    partial_dot(b_gpu,b_gpu,gpu_buffer1,block=(512,1,1),grid=(4096,1,1))\n","    partial_red(gpu_buffer1,gpu_buffer2,block=(512,1,1),grid=(8,1,1))\n","    cuda.memcpy_dtoh(cpu_buffer1,gpu_buffer2)\n","    cpu_buffer2[1]= np.sum(cpu_buffer1)\n","    \n","    return cpu_buffer2[0]/cpu_buffer2[1]\n"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T09:27:41.159002Z","iopub.status.busy":"2023-01-18T09:27:41.158555Z","iopub.status.idle":"2023-01-18T09:27:45.589228Z","shell.execute_reply":"2023-01-18T09:27:45.588124Z","shell.execute_reply.started":"2023-01-18T09:27:41.158963Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["527 µs ± 311 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"]}],"source":["a = np.random.random(128*128*128).astype(np.float64)\n","b = np.random.random(128*128*128).astype(np.float64)\n","a_gpu  = cuda.mem_alloc(a.nbytes)\n","b_gpu  = cuda.mem_alloc(b.nbytes)\n","cuda.memcpy_htod(a_gpu,a)\n","cuda.memcpy_htod(b_gpu,b)\n","c_gpu = cuda.mem_alloc(int(a.nbytes/512))\n","d_gpu = cuda.mem_alloc(int(a.nbytes/(512*512)))\n","d = cuda.mem_alloc(8)\n","\n","c_buffer = np.zeros(8).astype(np.float64)\n","c2 = np.zeros(2).astype(np.float64)\n","\n","%timeit ans1= cal_dpdt(a_gpu,b_gpu,c_gpu,d_gpu,c_buffer,c2)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mod11 = SourceModule(\"\"\"\n","__global__\n","void plus_alpha_vector(double *x,  double *y, double *alpha)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    x[ind] = x[ind] + alpha[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","plus_alpha_gpu = mod11.get_function(\"plus_alpha_vector\")\n","\n"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T09:26:02.127423Z","iopub.status.busy":"2023-01-18T09:26:02.127072Z","iopub.status.idle":"2023-01-18T09:26:02.138009Z","shell.execute_reply":"2023-01-18T09:26:02.136995Z","shell.execute_reply.started":"2023-01-18T09:26:02.127395Z"},"trusted":true},"outputs":[],"source":["def testalpha(block):\n","    a = np.random.random(128*128*128).astype(np.float64)\n","    b = np.random.random(128*128*128).astype(np.float64)\n","    alpha = np.array([3.7]).astype(np.float64)\n","    alpha_gpu=cuda.mem_alloc(alpha.nbytes)\n","    a_gpu = cuda.mem_alloc(a.nbytes)\n","    b_gpu = cuda.mem_alloc(a.nbytes)\n","    cuda.memcpy_htod(a_gpu,a)\n","    cuda.memcpy_htod(b_gpu,b)\n","    cuda.memcpy_htod(alpha_gpu,alpha)\n","    %timeit plus_alpha_gpu(a_gpu,b_gpu,alpha_gpu,block=(block,1,1),grid=(int(128*128*128/block),1,1))\n","    return\n"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2023-01-18T09:26:10.734342Z","iopub.status.busy":"2023-01-18T09:26:10.733972Z","iopub.status.idle":"2023-01-18T09:26:18.343380Z","shell.execute_reply":"2023-01-18T09:26:18.342319Z","shell.execute_reply.started":"2023-01-18T09:26:10.734312Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["93.1 µs ± 8.05 ns per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"]}],"source":["testalpha(512)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["mod12 = SourceModule(\"\"\"\n","__global__\n","void subtract_alpha_vector(double *x,  double *y, double *alpha)\n","{\n","    int R1 = blockIdx.x * blockDim.x + threadIdx.x;\n","    int ind = R1;\n","    x[ind] = x[ind] - alpha[0]*y[ind];\n","            \n","}\n","\"\"\")\n","\n","sub_alpha_gpu = mod12.get_function(\"subtract_alpha_vector\")\n","a = np.random.random(128*128*128).astype(np.float64)\n","b = np.random.random(128*128*128).astype(np.float64)\n","alpha = np.array([3.7]).astype(np.float64)\n","c = a - alpha[0] *b\n","sub_alpha_gpu(cuda.InOut(a),cuda.In(b),cuda.In(alpha),block=(512,1,1),grid=(4096,1,1))\n","print(c[0:4])\n","print(a[0:4])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def cpu_minres_1iter(A,x0,b):\n","    x = np.array(x0)\n","    r = b - A @ x0\n","    p0 = np.array(r)\n","    s0 = A @ p0\n","    p1 = np.array(p0)\n","    s1 = np.array(s0)\n","    \n","    p2 = np.ndarray.copy(p1)\n","    p1 = np.ndarray.copy(p0)\n","    s2 = np.ndarray.copy(s1)\n","    s1 = np.ndarray.copy(s0)\n","    alpha = np.dot(r,s1)/np.dot(s1,s1)\n","    x = x + alpha * p1\n","    r = r - alpha * s1\n","    p0 = np.ndarray.copy(s1)\n","    s0 = A @ s1\n","    beta1 = np.dot(s0,s1)/np.dot(s1,s1)\n","    p0 = p0 - beta1* p1\n","    s0 = s0 - beta1* s1\n","    \n","    return x, r"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["x_exact = np.ones(128*128*128).astype(np.float64)\n","b = A @ x_exact\n","x0 = np.zeros_like(x_exact)\n","[x,r]=cpu_minres_1iter(A,x0,b)\n","print(x)\n","print(r)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def gpu_minres_1iter(x0,b):\n","    #x = np.array(x0)\n","    #r = b - A @ x0\n","    #p0 = np.array(r)\n","    #s0 = A @ p0\n","    #p1 = np.array(p0)\n","    #s1 = np.array(s0)\n","    \n","    #allocating memory\n","    x=np.zeros_like(x0).astype(np.float64)\n","    r=np.zeros_like(x0).astype(np.float64)\n","\n","    cst_one=np.array([1.0]).astype(np.float64)\n","    cst_neone=np.array([-1.0]).astype(np.float64)\n","    \n","    alpha=np.array([1.0]).astype(np.float64)\n","    beta1=np.array([1.0]).astype(np.float64)\n","    beta2=np.array([1.0]).astype(np.float64)\n","\n","\n","\n","    \n","    x0_gpu = cuda.mem_alloc(x0.nbytes)\n","    x_gpu = cuda.mem_alloc(x0.nbytes)\n","    b_gpu = cuda.mem_alloc(x0.nbytes)\n","    r_gpu = cuda.mem_alloc(x0.nbytes)\n","    p0_gpu = cuda.mem_alloc(x0.nbytes)\n","    p1_gpu = cuda.mem_alloc(x0.nbytes)\n","    p2_gpu = cuda.mem_alloc(x0.nbytes)\n","\n","    \n","    s0_gpu = cuda.mem_alloc(x0.nbytes)\n","    s1_gpu = cuda.mem_alloc(x0.nbytes)\n","    s2_gpu = cuda.mem_alloc(x0.nbytes)\n","\n","    \n","    one_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    neone_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    \n","    alpha_gpu = cuda.mem_alloc(alpha.nbytes)\n","    beta1_gpu = cuda.mem_alloc(beta1.nbytes)\n","    beta2_gpu = cuda.mem_alloc(beta2.nbytes)\n","\n","    \n","    gpu_buffer1 = cuda.mem_alloc(int(a.nbytes/512))\n","    gpu_buffer2 = cuda.mem_alloc(int(a.nbytes/(512*512)))\n","    \n","    cpu_buffer_1=np.zeros(8).astype(np.float64)\n","    cpu_buffer_2f=np.zeros(2).astype(np.float64)\n","    cpu_buffer_3=np.zeros(1).astype(np.float64)\n","\n","\n","    \n","    temp = cuda.mem_alloc(x0.nbytes)\n","    \n","    #print(\"allocating completed\")\n","    \n","    #copy data\n","    cuda.memcpy_htod(x0_gpu, x0)\n","    cuda.memcpy_htod(b_gpu, b)\n","\n","    cuda.memcpy_htod(one_gpu, cst_one)\n","    cuda.memcpy_htod(neone_gpu, cst_neone)\n","    \n","    #print(\"memory copy completed, begin kernel computing\")\n","\n","    #x = np.array(x0)\n","    cpy_gpu(x0_gpu,x_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #r = b - A @ x0\n","    spmv_gpu_64(x0_gpu,temp,block=(8,8,8), grid=(16,16,16))\n","    \n","    apxby_gpu_1d(\n","        b_gpu,temp,r_gpu,one_gpu,neone_gpu,\n","        block=(512,1,1), grid=(16*16*16,1,1))\n","    \n","    #p0 = np.array(r)\n","    cpy_gpu(r_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s0 = A @ p0\n","    spmv_gpu_64(p0_gpu,s0_gpu,block=(8,8,8), grid=(16,16,16))\n","    \n","    #p1 = np.array(p0)\n","    cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s1 = np.array(s0)\n","    cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    print(\"pre-loop completed, begin iters...\")\n","    \n","    #p2 = np.ndarray.copy(p1)\n","    cpy_gpu(p1_gpu,p2_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","    #p1 = np.ndarray.copy(p0)\n","    cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s2 = np.ndarray.copy(s1)\n","    cpy_gpu(s1_gpu,s2_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s1 = np.ndarray.copy(s0)\n","    cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","    \n","    #alpha = np.dot(r,s1)/np.dot(s1,s1)\n","    cpu_buffer_3[0] = cal_dpdt(r_gpu,s1_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","    cuda.memcpy_htod(alpha_gpu, cpu_buffer_3)\n","    \n","    #x = x + alpha * p1\n","    plus_alpha_gpu(x_gpu,p1_gpu,alpha_gpu,block=(512,1,1),grid=(4096,1,1))\n","    \n","    #r = r - alpha * s1\n","    sub_alpha_gpu(r_gpu,s1_gpu,alpha_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","    \n","    #p0 = np.ndarray.copy(s1)\n","    cpy_gpu(s1_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","    \n","    #s0 = A @ s1\n","    spmv_gpu_64(s1_gpu,s0_gpu,block=(8,8,8), grid=(16,16,16))\n","\n","    #beta1 = np.dot(s0,s1)/np.dot(s1,s1)\n","    cpu_buffer_3[0] = cal_dpdt(s0_gpu,s1_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","    cuda.memcpy_htod(beta1_gpu, cpu_buffer_3)\n","    \n","    #p0 = p0 - beta1* p1\n","    sub_alpha_gpu(p0_gpu,p1_gpu,beta1_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","    \n","    #s0 = s0 - beta1* s1\n","    sub_alpha_gpu(s0_gpu,s1_gpu,beta1_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","    \n","    print(\"calculation completed, writing back...\")\n","    \n","    cuda.memcpy_dtoh(x,x_gpu)\n","    cuda.memcpy_dtoh(r,r_gpu)\n","\n","    print(\"finished\")\n","    return x,r\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["gpu_minres_1iter(x0,b)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-01-17T13:19:55.139749Z","iopub.status.busy":"2023-01-17T13:19:55.139270Z","iopub.status.idle":"2023-01-17T13:19:55.163929Z","shell.execute_reply":"2023-01-17T13:19:55.162656Z","shell.execute_reply.started":"2023-01-17T13:19:55.139715Z"},"trusted":true},"outputs":[],"source":["def gpu_minres_v2(x0,b,maxit):\n","    #x = np.array(x0)\n","    #r = b - A @ x0\n","    #p0 = np.array(r)\n","    #s0 = A @ p0\n","    #p1 = np.array(p0)\n","    #s1 = np.array(s0)\n","    \n","    #allocating memory\n","    ans=np.zeros_like(x0).astype(np.float64)\n","    cst_one=np.array([1.0]).astype(np.float64)\n","    cst_neone=np.array([-1.0]).astype(np.float64)\n","    \n","    alpha=np.array([1.0]).astype(np.float64)\n","    beta1=np.array([1.0]).astype(np.float64)\n","    beta2=np.array([1.0]).astype(np.float64)\n","\n","\n","\n","    \n","    x0_gpu = cuda.mem_alloc(x0.nbytes)\n","    x_gpu = cuda.mem_alloc(x0.nbytes)\n","    b_gpu = cuda.mem_alloc(x0.nbytes)\n","    r_gpu = cuda.mem_alloc(x0.nbytes)\n","    p0_gpu = cuda.mem_alloc(x0.nbytes)\n","    p1_gpu = cuda.mem_alloc(x0.nbytes)\n","    p2_gpu = cuda.mem_alloc(x0.nbytes)\n","\n","    \n","    s0_gpu = cuda.mem_alloc(x0.nbytes)\n","    s1_gpu = cuda.mem_alloc(x0.nbytes)\n","    s2_gpu = cuda.mem_alloc(x0.nbytes)\n","\n","    \n","    one_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    neone_gpu = cuda.mem_alloc(cst_one.nbytes)\n","    \n","    alpha_gpu = cuda.mem_alloc(alpha.nbytes)\n","    beta1_gpu = cuda.mem_alloc(beta1.nbytes)\n","    beta2_gpu = cuda.mem_alloc(beta2.nbytes)\n","\n","    \n","    gpu_buffer1 = cuda.mem_alloc(int(a.nbytes/512))\n","    gpu_buffer2 = cuda.mem_alloc(int(a.nbytes/(512*512)))\n","    \n","    cpu_buffer_1=np.zeros(8).astype(np.float64)\n","    cpu_buffer_2f=np.zeros(2).astype(np.float64)\n","    cpu_buffer_3=np.zeros(1).astype(np.float64)\n","\n","\n","    \n","    temp = cuda.mem_alloc(x0.nbytes)\n","    \n","    #print(\"allocating completed\")\n","    \n","    #copy data\n","    cuda.memcpy_htod(x0_gpu, x0)\n","    cuda.memcpy_htod(b_gpu, b)\n","\n","    cuda.memcpy_htod(one_gpu, cst_one)\n","    cuda.memcpy_htod(neone_gpu, cst_neone)\n","    \n","    #print(\"memory copy completed, begin kernel computing\")\n","\n","    #x = np.array(x0)\n","    cpy_gpu(x0_gpu,x_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #r = b - A @ x0\n","    spmv_gpu_64(x0_gpu,temp,block=(8,8,8), grid=(16,16,16))\n","    \n","    apxby_gpu_1d(\n","        b_gpu,temp,r_gpu,one_gpu,neone_gpu,\n","        block=(512,1,1), grid=(16*16*16,1,1))\n","    \n","    #p0 = np.array(r)\n","    cpy_gpu(r_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s0 = A @ p0\n","    spmv_gpu_64(p0_gpu,s0_gpu,block=(8,8,8), grid=(16,16,16))\n","    \n","    #p1 = np.array(p0)\n","    cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    #s1 = np.array(s0)\n","    cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","    \n","    print(\"pre-loop completed, begin iters...\")\n","    \n","    for iter in range(1,maxit):\n","    \n","        #p2 = np.ndarray.copy(p1)\n","        cpy_gpu(p1_gpu,p2_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #p1 = np.ndarray.copy(p0)\n","        cpy_gpu(p0_gpu,p1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #s2 = np.ndarray.copy(s1)\n","        cpy_gpu(s1_gpu,s2_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","        #s1 = np.ndarray.copy(s0)\n","        cpy_gpu(s0_gpu,s1_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","\n","        #alpha = np.dot(r,s1)/np.dot(s1,s1)\n","        cpu_buffer_3[0] = cal_dpdt(r_gpu,s1_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","        cuda.memcpy_htod(alpha_gpu, cpu_buffer_3)\n","\n","        #x = x + alpha * p1\n","        plus_alpha_gpu(x_gpu,p1_gpu,alpha_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","        #r = r - alpha * s1\n","        sub_alpha_gpu(r_gpu,s1_gpu,alpha_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","\n","        #p0 = np.ndarray.copy(s1)\n","        cpy_gpu(s1_gpu,p0_gpu,block=(512,1,1),grid=(16*16*16,1,1))\n","\n","\n","        #s0 = A @ s1\n","        spmv_gpu_64(s1_gpu,s0_gpu,block=(8,8,8), grid=(16,16,16))\n","\n","        #beta1 = np.dot(s0,s1)/np.dot(s1,s1)\n","        cpu_buffer_3[0] = cal_dpdt(s0_gpu,s1_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","        cuda.memcpy_htod(beta1_gpu, cpu_buffer_3)\n","\n","        #p0 = p0 - beta1* p1\n","        sub_alpha_gpu(p0_gpu,p1_gpu,beta1_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","\n","        #s0 = s0 - beta1* s1\n","        sub_alpha_gpu(s0_gpu,s1_gpu,beta1_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","        if iter>1:\n","\n","                #beta2 = np.dot(s0,s2)/np.dot(s2,s2)\n","                cpu_buffer_3[0] = cal_dpdt(s0_gpu,s2_gpu,gpu_buffer1,gpu_buffer2,cpu_buffer_1,cpu_buffer_2f)\n","                cuda.memcpy_htod(beta2_gpu, cpu_buffer_3)\n","\n","                #p0 = p0 - beta2* p2\n","                sub_alpha_gpu(p0_gpu,p2_gpu,beta2_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","                #s0 = s0 - beta2* s2\n","                sub_alpha_gpu(s0_gpu,s2_gpu,beta2_gpu,block=(512,1,1),grid=(4096,1,1))\n","\n","    \n","    \n","    #print(\"calculation completed, writing back...\")\n","    \n","    cuda.memcpy_dtoh(x,x_gpu)\n","    cuda.memcpy_dtoh(r,r_gpu)\n","\n","    #print(\"finished\")\n","    return x,r\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["See GPU information:"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["!nvidia-smi"]}],"metadata":{"kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"vscode":{"interpreter":{"hash":"4500649f3376875055274a6ea5762786a730155ceb79c8798b9983f2d85af345"}}},"nbformat":4,"nbformat_minor":4}
